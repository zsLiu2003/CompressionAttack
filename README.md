# CompressionAttack

### Attack Methodologies

1. **HardCom (Hard Compression Attack)**
   - Targets rule-based/algorithmic compression methods (e.g., Selective Context, LLMLingua)
   - Uses token/word/target-level manipulation and adversarial prompt injection

2. **SoftCom (Soft Compression Attack)**  
   - Targets learned compression models (e.g., AutoCompressor, ICAE)
   - Uses gradient-based optimization to craft adversarial compressed representations
   - Manipulates the learned compression latent space

## ğŸ—ï¸ Project Structure

```
Compressionattack/
â”‚
â”œâ”€â”€ hardcom/                           # HardCom: Attacks on Rule-based Compression
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ attacks/                  # Attack implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ attack_llmlingua.py   # Attack against LLMLingua
â”‚   â”‚   â”‚   â””â”€â”€ baseline_prompt.py    # Baseline attacks
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ defense/                  # Defense mechanisms
â”‚   â”‚   â”‚   â”œâ”€â”€ ppl_detection.py      # Perplexity-based detection
â”‚   â”‚   â”‚   â”œâ”€â”€ prevention_detection.py # prevention-based detection
â”‚   â”‚   â”‚   â””â”€â”€ LLM_detection.py      # LLM-based detection
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ evaluators/               # Evaluation tools
â”‚   â”‚   â”‚   â”œâ”€â”€ tool_selection_test.py
â”‚   â”‚   â”‚   â”œâ”€â”€ QA_test.py
â”‚   â”‚   â”‚   â”œâ”€â”€ stealthy_*.py         # Stealthiness metrics
â”‚   â”‚   â”‚   â””â”€â”€ F1_score.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ get_ppl.py            # PPL calculation
â”‚   â”‚   â”‚   â”œâ”€â”€ get_edit_token.py     # Token manipulation
â”‚   â”‚   â”‚   â””â”€â”€ inference.py          # Model inference
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ data/                     # Datasets and prompts
â”‚   â”‚       â”œâ”€â”€ data.json
â”‚   â”‚       â”œâ”€â”€ squad_QA_dataset.json
â”‚   â”‚       â””â”€â”€ *.txt                 # Prompt templates
â”‚   â”‚
â”‚   â”œâ”€â”€ examples/                     # Demo applications
â”‚   â”‚   â”œâ”€â”€ agent/                    # Agent-based examples
â”‚   â”‚   â””â”€â”€ Tool_selection/           # Tool selection attacks
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                     # Configuration
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ softcom/                           # SoftCom: Attacks on Learned Compression
â”‚   â”‚
â”‚   â”œâ”€â”€ AutoCompressors/              # Target: AutoCompressor (compression model)
â”‚   â”‚   â”œâ”€â”€ auto_compressor.py        # AutoCompressor implementation
â”‚   â”‚   â”œâ”€â”€ train.py                  # Model training
â”‚   â”‚   â”œâ”€â”€ evaluate_*.py             # Evaluation on various tasks
â”‚   â”‚   â”œâ”€â”€ modeling_*.py             # Model architectures
â”‚   â”‚   â””â”€â”€ run/                      # Training/eval scripts
â”‚   â”‚
â”‚   â”œâ”€â”€ ComAttack/                    # Attack implementations against soft compression
â”‚   â”‚   â”œâ”€â”€ icae_attack*.py           # Attacks using ICAE
â”‚   â”‚   â”œâ”€â”€ modeling_icae*.py         # ICAE model for attacks
â”‚   â”‚   â”œâ”€â”€ prompt_benchmark.py       # Benchmarking tools
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ open_source_code/         # Core attack code
â”‚   â”‚       â”œâ”€â”€ icae_attack*.py       # Various attack scenarios
â”‚   â”‚       â”œâ”€â”€ icae_QA*.py           # QA-specific attacks
â”‚   â”‚       â”œâ”€â”€ icae_recommend*.py    # Recommendation attacks
â”‚   â”‚       â”œâ”€â”€ evaluate_*.py         # Attack evaluation
â”‚   â”‚       â”œâ”€â”€ modeling_icae*.py     # ICAE architectures
â”‚   â”‚       â”œâ”€â”€ dataloader/           # Data loading utilities
â”‚   â”‚       â””â”€â”€ *.sh                  # Execution scripts
â”‚   â”‚
â”‚   â””â”€â”€ Comattack_dataset/            # Datasets for soft attacks
â”‚       â”œâ”€â”€ squad/                    # SQuAD QA dataset
â”‚       â”œâ”€â”€ recommend/                # Product recommendation data
â”‚       â””â”€â”€ *.json                    # Attack-specific datasets
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended for training)
- PyTorch 2.0+
- Transformers 4.30+

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd Compressionattack
```

2. Install dependencies:
```bash
# Core dependencies
pip install torch transformers datasets accelerate

# For hard compression attacks
pip install llmlingua sentence-transformers bert-score python-Levenshtein flask

# For soft compression attacks
pip install flash-attn sentencepiece packaging wandb

# Optional: For defense mechanisms
pip install language-tool-python nltk
```

3. Configure model paths:
```bash
cd hardcom
cp config.py.example config.py  # If available
# Edit config.py with your model paths
```

## ğŸ“š Usage

### HardCom: Attacking Rule-based Compression

HardCom attacks exploit algorithmic compression methods that use perplexity or other heuristics to select tokens for removal.

#### Running HardCom Attacks

```bash
cd hardcom

# Configure your model paths
vim config.py  # Set paths for compression and target models

# Attack LLMLingua compression
python src/attacks/attack_llmlingua.py

# Run evaluation on different tasks
python src/evaluators/QA_test.py              # Question Answering
python src/evaluators/tool_selection_test.py  # Tool Selection
python src/evaluators/stealthy_character.py   # Stealthiness metrics
```

### SoftCom: Attacking Learned Compression

SoftCom attacks target neural compression models that learn to compress prompts into continuous representations.

#### Target Compression Models
- **AutoCompressor**: Learns summary vectors for context compression
- **ICAE (In-Context Auto-Encoder)**: End-to-end differentiable compression

#### Running SoftCom Attacks

```bash
cd softcom/ComAttack

# Attack with ICAE on different tasks
bash icae_attack_soft.sh                      # Basic ICAE attack

# QA-specific attacks
bash open_source_code/icae_QA.sh              # Question Answering attack
python open_source_code/evaluate_QA.py        # Evaluate QA attack

# Recommendation attacks
bash open_source_code/icae_recommend_keyword_dataset_improve.sh   # Improve target
bash open_source_code/icae_recommend_keyword_dataset_degrade.sh   # Degrade best
python open_source_code/evaluate_rec_improve.py                   # Evaluate
```

#### Training Target Compression Models (Optional)

If you want to train your own compression models to attack:

```bash
cd softcom/AutoCompressors

bash run/train_llama.sh

# Evaluate compression performance
bash run/eval_llama.sh
python evaluate_qa.py
python evaluate_recommend.py
```
### Defense Mechanisms

The project includes multiple defense methods:

```bash
cd hardcom/src/defense

# Perplexity-based detection
python ppl_detection.py

#Prevention-based detection
python prevention_detection.py

# LLM-based detection
python LLM_detection.py
```

## ğŸ¯ Attack Scenarios

Both HardCom and SoftCom can be applied to various downstream tasks:

### 1. Question Answering (QA) Attack

**HardCom Approach**:
```bash
cd hardcom
python src/attacks/attack_llmlingua.py --task qa --dataset squad
python src/evaluators/QA_test.py
```


**SoftCom Approach**:
```bash
cd softcom/ComAttack
bash open_source_code/icae_QA.sh
python open_source_code/evaluate_QA.py
```

### 2. Product Recommendation Attack

**HardCom Approach**:
```bash
cd hardcom
python src/evaluators/product_recommendation_test.py
```

**SoftCom Approach**:
```bash
cd softcom/ComAttack/open_source_code

# Improve target product ranking
bash icae_recommend_keyword_dataset_improve.sh
python evaluate_rec_improve.py

# Degrade best product ranking  
bash icae_recommend_keyword_dataset_degrade.sh
python evaluate_rec_degrade.py
```

## ğŸ“Š Evaluation Metrics

The framework provides comprehensive evaluation metrics:

### Stealthiness Metrics
- **Composite Stealth Score**: `Î» Â· cosine_sim(C, CÌƒ) + (1-Î») Â· BERTScore(C, CÌƒ)`
- **Semantic Similarity**: Cosine similarity using SentenceTransformers
- **BERT-Score**: F1 score with baseline rescaling
- **Character-level Similarity**: Normalized edit distance

### Attack Success Metrics
- **Attack Success Rate (ASR)**: Percentage of successful adversarial manipulations
- **Task Performance Degradation**: Drop in target task accuracy
- **F1 Score**: Question answering accuracy
- **Recommendation Rank Change**: Position change of target/best items

## ğŸ›¡ï¸ Defense Evaluation

Test defense mechanisms against attacks:

```bash
cd hardcom/src/defense

# Calculate clean PPL threshold
python calculate_clean_ppl_threshold.py

# Test PPL-based detection
python ppl_detection.py --threshold 80.0

# Test LLM detection
python LLM_detection.py
```

## ğŸ“ Datasets

The project includes several datasets:
- **SQuAD**: Question answering dataset
- **Product Recommendation**: E-commerce product datasets
- **Tool Selection**: Agent tool selection scenarios
- **Custom Datasets**: Keyword-injected and adversarial datasets

Datasets are located in:
- `hardcom/src/data/`
- `softcom/Comattack_dataset/`

## ğŸ”§ Configuration

Edit `hardcom/config.py` to set up model paths:

```python
# Model paths
COMPRESSION_MODEL_PATH = "path/to/compression-model"
LARGE_MODEL_PATH = "path/to/Qwen3-32B"
LLAMA_PATH = "path/to/model"
MISTRAL_PATH = "path/to/Mistral-7B-Instruct-v0.2"

# CUDA settings
DEFAULT_CUDA_DEVICE = "cuda:0"
```